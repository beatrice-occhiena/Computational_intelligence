{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Author:** Beatrice Occhiena s314971. See [`LICENSE`](https://github.com/beatrice-occhiena/Computational_intelligence/blob/main/LICENSE) for details.\n",
    "- institutional email: `S314971@studenti.polito.it`\n",
    "- personal email: `beatrice.occhiena@live.it`\n",
    "- github repository: [https://github.com/beatrice-occhiena/Computational_intelligence.git](https://github.com/beatrice-occhiena/Computational_intelligence.git)\n",
    "\n",
    "**Resources:** These notes are the result of additional research and analysis of the lecture material presented by Professor Giovanni Squillero for the Computational Intelligence course during the academic year 2023-2024 @ Politecnico di Torino. They are intended to be my attempt to make a personal contribution and to rework the topics covered in the following resources.\n",
    "- [https://github.com/squillero/computational-intelligence](https://github.com/squillero/computational-intelligence)\n",
    "- Stuart Russel, Peter Norvig, *Artificial Intelligence: A Modern Approach* [3th edition]\n",
    "\n",
    ".\n",
    "\n",
    ".\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem Solving by Searching\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Why search?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Search techniques are utilized in problem-solving scenarios when there is a clear, predefined goal that needs to be achieved, and the problem can be logically broken down into different states and actions.\n",
    "\n",
    "Search algorithms are essential for tackling problems in various domains and are especially useful in cases when:\n",
    "- The problem's **complexity** is beyond straightforward mathematical modeling or doesn't have a known analytical solution.\n",
    "- We **lack prior knowledge** of the exact sequence of actions leading to a solution.\n",
    "- We intend to systematically explore a **large solution space**, requiring an examination of various paths to find the best one.\n",
    "- We seek **optimal or near-optimal solutions** in extensive search spaces.\n",
    "\n",
    "### Problem solving agent\n",
    "A problem-solving agent is a type of goal-based agent capable of determining a sequence of actions leading to a desired goal. This agent achieves this by exploring the problem's state space, which encompasses all potential states reachable from the initial state through a sequence of actions.\n",
    "\n",
    "The agent's program comprises two key components:\n",
    "- **Problem & Goal Formulation** This entails the process of deciding which actions and states to consider based on the specified goal. ðŸ—ºï¸ðŸŽ¯..\n",
    "- **Search Algorithm** This involves determining the next action to take given the current state in order to progress toward the goal. ðŸ§­..\n",
    "\n",
    "### Conditions for solving problems by searching\n",
    "While path search algorithms can be applied to a wide range of problems, there are some conditions and considerations that make them more suitable for certain types of problems.\n",
    "\n",
    "When the task environment is\n",
    "- discrete\n",
    "- fully observable\n",
    "- deterministic\n",
    "- static\n",
    "- completelly known\n",
    "\n",
    "> In this case, the agent can be said to have `full control` of the environment, therefore it can plan ahead and choose a sequence of actions that will lead to the desired goal. The process of finding a sequence of actions is called *search*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem definition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A problem can be formally defined by the following components:\n",
    "1. **Initial state** The state in which the agent begins. $s_0$\n",
    "2. **Set of actions** The set of actions available to the agent in each state. $\\mathcal{A}(s)=\\{a_1, a_2, \\dots, a_n\\}$\n",
    "3. **Transition model** A description of what each action does. $\\mathcal{S}(s,a)=s'$\n",
    "4. **Goal test** A function that determines whether a given state is a goal state. $\\mathcal{G}(s)$\n",
    "5. **Path cost** A function that assigns a numeric cost to each path. It is assumed that the cost of a path is the sum of the costs of its actions, i.e. the sum of each step's cost. $g(s_0, a_1, \\dots, a_n)=\\sum_{i=1}^n c(s_i, a_i, s_{i+1})$\n",
    "\n",
    "### State space\n",
    "The state space is the set of all states reachable from the initial state by any sequence of actions. It is denoted by $\\mathcal{S}$. The state space is a **directed graph**, where \n",
    "- the nodes represent `states` â­•..\n",
    "- the edges represent `actions` âž¡ï¸..\n",
    "\n",
    "### Searching for solutions\n",
    "A solution to a problem is a sequence of actions that leads *from the initial state to a goal state*. A solution is `optimal` if it has the lowest path cost among all solutions.\n",
    "\n",
    "Depending on the way we want our search algorithm to explore the state space, we can distinguish between two types of search.\n",
    "\n",
    "##### 1 - ðŸŒ³ Tree search ðŸŒ³\n",
    "In a tree search, the search algorithm explores a search tree without considering whether it has visited a state before. It doesn't keep track of the states it has already explored.\n",
    "\n",
    "$\\implies$ different nodes can represent the same state.\n",
    "\n",
    "The initial state of the problem serves as the `root` node of the tree. As the search algorithm progresses, it `expands nodes` by considering possible actions and generating child nodes for each state that can be reached.\n",
    "- `o` `Memory usage`: It tends to use less memory because it only maintains the current tree and doesn't remember visited states.\n",
    "- `x` `Redundancy`: It may explore the same state multiple times, leading to inefficiency.\n",
    "- `x` `Un-completeness`: It may not find a solution even if one exists, due to infinite loops in a space with cycles.\n",
    "\n",
    "Tree search is typically used in cases where memory resources are limited and revisiting states isn't an issue. It's suitable for cases where the solution is guaranteed to be found quickly or where the state space doesn't contain cycles.\n",
    "  \n",
    "##### 2 - ðŸ“Š Graph search ðŸ“Š\n",
    "In graph search, the search algorithm keeps track of the states it has already explored, ensuring that it doesn't revisit them. This is crucial for practical problem-solving because revisiting states can be inefficient and may lead to infinite loops.\n",
    "\n",
    "$\\implies$ nodes represent unique states.\n",
    "\n",
    "- `x` `Memory usage`: It tends to use more memory because it needs an additional data structure to keep track of visited states.\n",
    "- `o` `Efficient exploration`: In graph search, the exploration extends across the entire state space, keeping track of visited states to avoid revisiting them. It maintains a more comprehensive record of the explored states.\n",
    "- `o` `Completeness`: It is guaranteed to find a solution if one exists, as it doesn't get stuck in infinite loops.\n",
    "\n",
    "Graph search is used when memory resources are more abundant, and the state space may contain cycles or when it's essential to guarantee that a solution, if it exists, will be found."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data structures, functions and terminology"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### State space\n",
    "In search problems, agents treat states and actions as `atomic` entities. This means that they don't need to know the internal structure of states and actions, but only how to compare them and how to apply actions to states.\n",
    "\n",
    "Depending on the problem, the state space can be represented as a graph, a matrix, or any appropriate data structure.\n",
    "\n",
    "> This is where we need to unleash all our inventiveness and creativity to come up with a representation that allows us to effectively represent every aspect of the problem.\n",
    "\n",
    "Our representation has to:\n",
    "- exhaustive = contain all the information necessary to describe the problem\n",
    "- abstract = be as compact as possible, to avoid wasting memory resources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: 8-puzzle problem\n",
    "initial_state = [[1, 2, 3], [4, 5, 6], [7, 8, 0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Actions\n",
    "Actions are the atomic entities that agents can perform to change the state of the environment. They are usually implemented by two functions:\n",
    "- `actions(state)` returns the set of actions available in a given state.\n",
    "- `apply_action(state, action)` returns the state that results from applying an action to a given state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: 8-puzzle problem\n",
    "def actions(state):\n",
    "    actions_list = []\n",
    "    for i in range(3):\n",
    "        for j in range(3):\n",
    "            if state[i][j] == 0:\n",
    "                if i > 0:\n",
    "                    actions_list.append('up')\n",
    "                if i < 2:\n",
    "                    actions_list.append('down')\n",
    "                if j > 0:\n",
    "                    actions_list.append('left')\n",
    "                if j < 2:\n",
    "                    actions_list.append('right')\n",
    "    return actions_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: 8-puzzle problem\n",
    "def apply_action(state, action):\n",
    "    # Create a copy of the current state to avoid modifying the original state\n",
    "    new_state = [row[:] for row in state]\n",
    "\n",
    "    # Find the row and column of the blank (0) tile\n",
    "    for i in range(3):\n",
    "            for j in range(3):\n",
    "                if state[i][j] == 0:\n",
    "                    empty_row, empty_col = i, j\n",
    "\n",
    "    # Perform the action by swapping the blank tile and an adjacent tile\n",
    "    if action == \"up\":\n",
    "        new_state[empty_row][empty_col], new_state[empty_row - 1][empty_col] = (new_state[empty_row - 1][empty_col], new_state[empty_row][empty_col],)\n",
    "    elif action == \"down\":\n",
    "        new_state[empty_row][empty_col], new_state[empty_row + 1][empty_col] = (new_state[empty_row + 1][empty_col], new_state[empty_row][empty_col],)\n",
    "    elif action == \"left\":\n",
    "        new_state[empty_row][empty_col], new_state[empty_row][empty_col - 1] = (new_state[empty_row][empty_col - 1], new_state[empty_row][empty_col],)\n",
    "    elif action == \"right\":\n",
    "        new_state[empty_row][empty_col], new_state[empty_row][empty_col + 1] = (new_state[empty_row][empty_col + 1], new_state[empty_row][empty_col],)\n",
    "\n",
    "    return new_state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Frontier\n",
    "The set of all *nodes available for expansion at any given point* is called the frontier. These nodes have been generated but not yet expanded.\n",
    "- **init** The frontier will initially contain only the initial state.\n",
    "- **loop** The process of expanding nodes on the frontier continues until \n",
    "  - ðŸŽ¯ a goal state is found \n",
    "  - ðŸš« there are no more nodes to expand => no solution exists\n",
    "  - âœ‹ðŸ» a predefined limit is reached\n",
    "\n",
    "It is implemented as a `queue` in which the order of the nodes to be extracted is determined by the search strategy.\n",
    "- FIFO\n",
    "- LIFO\n",
    "- Priority\n",
    "\n",
    "ðŸ§ðŸ»ðŸ§ðŸ»â€â™‚ï¸ðŸ§ðŸ»â€â™€ï¸ðŸ§ðŸ»ðŸ§ðŸ»â€â™‚ï¸ðŸ§ðŸ»â€â™€ï¸... Next!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explored set\n",
    "ðŸ“Š! The explored set is a data structure that keeps track of the *already visited states*. And its presence is what distinguishes graph search from tree search!\n",
    "\n",
    "It is implemented as a `set` or `hash table` to facilitate the search for visited states.\n",
    "\n",
    "ðŸ§ðŸ»â€â™€ï¸âœ‹ðŸ».. Not you again! ðŸ§ðŸ»ðŸ§ðŸ»â€â™‚ï¸ðŸ§ðŸ»â€â™€ï¸ðŸ§ðŸ»ðŸ§ðŸ»â€â™‚ï¸ðŸ§ðŸ»â€â™€ï¸"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Expanding a node\n",
    "When a node is `extracted` from the frontier, it is `expanded` by generating its child nodes.\n",
    "- **generate** Children are obtained by applying each possible action to the current state.\n",
    "- **add** The newly generated successor nodes are added to the frontier.\n",
    "\n",
    "ðŸ“Š! For graph search, the newly generated nodes are only added to the frontier if they haven't been visited before. They are checked against the `explored set` to ensure that they are unique."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Goal check\n",
    "When a node is extracted from the frontier, it is checked to see if it is a goal state. If it is, the search is terminated and the solution is returned. Otherwise, the search continues.\n",
    "\n",
    "The check is implemented as a `function` that takes a state as input and returns a boolean value. \n",
    "\n",
    "ðŸŽ¯ðŸ”???.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: 8-puzzle problem\n",
    "def goal_check(state):\n",
    "    return state == [[1, 2, 3], [4, 5, 6], [7, 8, 0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: 8-puzzle problem - graph search\n",
    "from queue import SimpleQueue\n",
    "\n",
    "# frontier\n",
    "frontier = SimpleQueue()\n",
    "frontier.put(initial_state)\n",
    "\n",
    "# explored set\n",
    "explored = set()\n",
    "\n",
    "while not frontier.empty():\n",
    "    # get the next state from the frontier\n",
    "    curr_state = frontier.get()\n",
    "    explored.add(curr_state)\n",
    "\n",
    "    # check if the current state is the goal state\n",
    "    if goal_check(curr_state):\n",
    "        print('Found!')\n",
    "        break\n",
    "\n",
    "    # add the new states to the frontier\n",
    "    for action in actions(curr_state):\n",
    "        new_state = apply_action(curr_state, action)\n",
    "        if new_state not in explored:\n",
    "            frontier.put(new_state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Path reconstruction, path cost & other node related information\n",
    "When the goal state is not representative of the solution (i.e. the sequence of actions needed to solve the problem), the path from the initial state to the goal state can be reconstructed in various ways. \n",
    "\n",
    "The total cost of the path is strictly related to the same principle, as it is the sum of the costs of each step in the path. And even if usually the step cost is the same for all actions, in some cases it may vary depending on the state or action.\n",
    "\n",
    "Other information about the node can be stored in the node itself. For example, the depth of the node in the tree, the action that led to the node, etc.\n",
    "\n",
    "To tackle these issues, we can use different approaches such as:\n",
    "\n",
    "- **parent pointers** In graph search, in which we don't want to revisit states, each node can contain a pointer to its only parent node. The path can be reconstructed by following the parent pointers of each node. This can be implemented by:\n",
    "  - a `dictionary` in which the key is the child node and the value is the parent node\n",
    "  - a `function` that takes the goal state as input and returns the list of states/actions leading to it\n",
    "- **recursive search** When using recursion for tree search, you would typically implement a recursive function that explores child nodes from a given state, and as it explores deeper into the tree, it can keep track of the parent-child relationships. The information about the path in this case is stored in the call stack, but keep in mind that for very deep trees, recursion may lead to stack overflow.\n",
    "- **node representation** In tree search, nodes and states do not coincide. Since I can guarantee that each node has a unique predecessor, I can store the path from the initial state to the goal only when I create a wrapper class for the nodes. This can be implemented by:\n",
    "  - a `class Node` that contains the state, the parent node, the path cost and other information about the node (e.g. depth, action, etc.)\n",
    "- **visual representation** In tree search, in which a state can have multiple parent nodes, we can find an inventive way to visually represent the path from the initial state to the goal state. This can be implemented by:\n",
    "  - a `graph` in which storing all possible node-states\n",
    "  - a `function` that adds an edge between the current node and its parent node\n",
    "  - a `function` to visualize the graph\n",
    "\n",
    "  (See https://github.com/squillero/computational-intelligence/blob/master/2023-24/4-friends.ipynb for an example)\n",
    "\n",
    "> Reconstructing the path surely can be a challenging memory-intensive task, but fortunately, it is not always necessary. In some cases, the goal state can be representative of the solution, and the path can be reconstructed by following the parent pointers of each node. In others we're only interested in finding if a solution exists, and not in the path itself.\n",
    "\n",
    "ðŸœ...ðŸœ..ðŸœ.....ðŸœ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Node class\n",
    "class Node:\n",
    "    def __init__(self, state, parent, action, depth, cost):\n",
    "        self.state = state\n",
    "        self.parent = parent\n",
    "        self.action = action\n",
    "        self.depth = depth\n",
    "        self.cost = cost\n",
    "        self.is_expanded = False\n",
    "    \n",
    "    def expand(self):\n",
    "        actions_list = actions(self.state)\n",
    "        children = []\n",
    "        for action in actions_list:\n",
    "            child_state = apply_action(self.state, action)\n",
    "            child = Node(child_state, self, action, self.depth + 1, self.cost + 1)\n",
    "            children.append(child)\n",
    "        self.is_expanded = True\n",
    "        return children"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Search strategies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Measuring search performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Uninformed search strategies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Breadth-first search (BFS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Depth-first search (DFS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Uniform-cost search (UCS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Depth-limited search (DLS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Iterative deepening search (IDS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bidirectional search (BDS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Beam search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Informed search strategies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Greedy best-first search (GBFS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A* search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "- search tree vs search graph: data structures\n",
    "  => treat states and actions as **atomic** entities\n",
    "\n",
    "## Search strategies\n",
    "Their performance is measured in terms of:\n",
    "- Completeness: is the algorithm guaranteed to find a solution when there is one?\n",
    "- Optimality: does the strategy find the best solution?\n",
    "- Time complexity: how long does it take to find a solution?\n",
    "- Space complexity: how much memory is needed to perform the search?\n",
    "Complexity depends on:\n",
    "- b: maximum branching factor of the search tree\n",
    "- d: depth of the least-cost solution\n",
    " \n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
